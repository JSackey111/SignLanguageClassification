# SignLanguageClassification
 Sync_Intern_Task4


In this project, I embarked on the task of classifying sign language symbols using Convolutional Neural Networks (CNNs). 
The initial steps involved setting up the essential tools within my Jupyter notebook, namely the Keras and TensorFlow libraries. 
These libraries formed the backbone for constructing and training our neural network.
With the foundational libraries in place, I delved into data manipulation and visualization by importing key libraries: Pandas for data manipulation, NumPy for numerical computations, and Matplotlib for data visualization.
I then proceeded to load the training and testing data, converting it into the preferred NumPy array format to make it compatible with the neural network.
I assigned unique class labels to each sign language symbol, spanning from A to Z, and illustrated some of these symbols alongside their corresponding labels. This step laid the groundwork for the subsequent training phase.
Training the CNN involved extracting intricate patterns from the sign language symbols. As the neural network progressed through the training process, it developed a deeper understanding of the subtle nuances that differentiate each symbol from the others.
Upon completing the training, I shifted focus to making predictions, deciphering the underlying meanings encoded in the test data symbols. 
To evaluate the effectiveness of the CNN model, I constructed a confusion matrix, which provided insights into the model's accuracy score. Notably, the CNN model achieved an impressive classification accuracy score of 93% in this endeavor.

In conclusion, the synergy between data, neural networks, and human expression was spotlighted. This reveals the limitless potential that emerges at the intersection of innovation and comprehension. 

